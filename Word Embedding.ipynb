{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867e694a-5f2b-45ab-abac-e3188a743061",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "Word2Vec是一种流行的词嵌入（Word Embedding）技术，由Tomas Mikolov等人在2013年提出。它是一种基于神经网络NNLM的语言模型，旨在通过学习词与词之间的上下文关系来生成词的密集向量表示。Word2Vec的核心思想是利用词在文本中的上下文信息来捕捉词之间的语义关系，从而使得语义相似或相关的词在向量空间中距离较近。\n",
    "```python\n",
    "vector(\"king\") - vector(\"man\") + vector(\"woman\") ≈ vector(\"queen\")\n",
    "```\n",
    "Word2Vec模型主要有两种架构：连续词袋模型CBOW(Continuous Bag of Words)是根据目标词上下文中的词对应的词向量, 计算并输出目标词的向量表示；Skip-Gram模型与CBOW模型相反, 是利用目标词的向量表示计算上下文中的词向量. 实践验证CBOW适用于小型数据集, 而Skip-Gram在大型语料中表现更好。\n",
    "- CBOW（Continuous Bag of Words）：根据上下文词预测中心词\n",
    "- Skip-gram：根据中心词预测上下文词\n",
    "  \n",
    "\n",
    "> **\"The cat is sleeping on the sofa.\"**\n",
    "\n",
    "#### CBOW的训练样本：\n",
    "我们设定窗口大小为 3（表示左右各三个词为上下文）。\n",
    "* 目标：预测中心词 \"sleeping\"\n",
    "* 上下文词是：[\"The\", \"cat\", \"is\", \"on\", \"the\", \"sofa\"]\n",
    "  \n",
    "#### Skip-gram 的训练样本：\n",
    "* 目标：用中心词\"sleeping\"预测它的上下文词。\n",
    "* 上下文词是：[\"The\", \"cat\", \"is\", \"on\", \"the\", \"sofa\"]\n",
    "* 会生成\"sleeping\"分别和上下文词的训练对\n",
    "\n",
    "\n",
    "相比于传统的高维稀疏表示（如One-Hot编码），Word2Vec生成的是低维（通常几百维）的密集向量，有助于减少计算复杂度和存储需求。Word2Vec模型可以很好地泛化到训练中未出现过的词，因为它是基于上下文信息学习的，而不是基于词典。但由于CBOW/Skip-Gram模型是基于局部上下文的，无法捕捉到长距离的依赖关系，缺乏整体的词与词之间的关系，因此在一些复杂的语义任务上表现不佳。\n",
    "\n",
    "*Question：OOV的泛化能力*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4cc27-d665-4f40-839d-76e33f8f318e",
   "metadata": {},
   "source": [
    "Gensim 是一个非常流行的 Python 工具库，用于训练 Word2Vec模型，它支持两种模型：CBOW 和 Skip-gram，可以通过设置参数`sg`来选择：`sg=0（default）`是CBOW， `sg=1`是Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1538d830-a011-4787-b83e-cd035f3a3cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mouse', 0.19911441206932068),\n",
       " ('floor', 0.17272186279296875),\n",
       " ('sleeping', 0.17018885910511017),\n",
       " ('back', 0.1528114527463913),\n",
       " ('sofa', 0.14595060050487518),\n",
       " ('on', 0.06408978253602982),\n",
       " ('she', 0.04652618616819382),\n",
       " ('goes', 0.0014541522832587361),\n",
       " ('a', -0.0027540235314518213),\n",
       " ('is', -0.013514946214854717)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "sentences = [\n",
    "    [\"the\", \"cat\", \"is\", \"sleeping\", \"on\", \"the\", \"sofa\"],\n",
    "    [\"a\", \"mouse\", \"runs\", \"across\", \"the\", \"floor\"],\n",
    "    [\"she\", \"opens\", \"one\", \"eye\"],\n",
    "    [\"then\", \"goes\", \"back\", \"to\", \"sleep\"]\n",
    "]\n",
    "model = Word2Vec(sentences, vector_size=100, window=8, min_count=1)\n",
    "model.wv.most_similar(positive=[\"cat\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
